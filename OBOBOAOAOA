[1mdiff --git a/diamonds.py b/diamonds.py[m
[1mindex 3a1582b..fa1132f 100644[m
[1m--- a/diamonds.py[m
[1m+++ b/diamonds.py[m
[36m@@ -22,7 +22,8 @@[m [mfrom sklearn.metrics.cluster import contingency_matrix;[m
 from sklearn.pipeline import make_pipeline;[m
 from sklearn.preprocessing import StandardScaler;[m
 [m
[31m-#Getting the diamonds[m
[32m+[m
[32m+[m[32m#Getting the dataset[m
 diamonds = pd.read_csv('https://raw.githubusercontent.com/raczandras/ML/main/diamonds.csv');[m
 [m
 atts = diamonds.drop('pricerange',axis=1);[m
[36m@@ -38,6 +39,10 @@[m [mdiamonds2 = diamonds;[m
 [m
 columns_titles= ["carat", "price", "x_length", "y_length", "z_length"];[m
 [m
[32m+[m[32m#The relationship of attributes[m
[32m+[m[32msns.pairplot(data=diamonds)[m
[32m+[m[32mplt.show()[m
[32m+[m
 #PCA[m
 pipe = make_pipeline(StandardScaler(), PCA());[m
 diamonds_pc_scaled=pipe.fit_transform(atts)[m
[36m@@ -124,9 +129,9 @@[m [mplt.title('Confusion matrix for TRAIN data (decision tree)');[m
 plot_confusion_matrix(class_tree, X_test, y_test, display_labels = target_names);[m
 plt.title('Confusion matrix for TEST data (decision tree)');[m
 [m
[31m-#Contingency[m
[32m+[m
 # Finding optimal cluster number[m
[31m-Max_K = 12;  # maximum cluster number[m
[32m+[m[32mMax_K = 31;  # maximum cluster number[m
 SSE = np.zeros((Max_K-2));[m
 DB = np.zeros((Max_K-2));[m
 for i in range(Max_K-2):[m
[36m@@ -159,4 +164,3 @@[m [mkmeans.fit(X_test);[m
 data_labels = kmeans.labels_;[m
 cm = contingency_matrix(y_test, kmeans.labels_);[m
 [m
[31m-[m
